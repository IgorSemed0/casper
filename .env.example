# Casper AI Configuration
# Copy this file to .env and fill in your actual values

# AI Provider Configuration
# Supports multiple providers: Gemini, OpenAI, Anthropic, local servers, etc.

# Google Gemini API (Recommended for vision tasks)
AI_REQUEST_URL=https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent
AI_TOKEN=your_gemini_api_key
AI_MODEL=gemini-2.0-flash-exp

# Alternative: OpenAI
# AI_REQUEST_URL=https://api.openai.com/v1/chat/completions
# AI_TOKEN=your_openai_api_key_here
# AI_MODEL=gpt-4o

# Alternative: Anthropic Claude
# AI_REQUEST_URL=https://api.anthropic.com/v1/messages
# AI_TOKEN=your_anthropic_api_key_here
# AI_MODEL=claude-3-5-sonnet-20241022

# Alternative: Local LLM (e.g., Ollama)
# AI_REQUEST_URL=http://localhost:11434/api/generate
# AI_TOKEN=not_needed_for_local
# AI_MODEL=llama3.2-vision

# Optional: Additional AI Settings
# AI_MAX_TOKENS=1024
# AI_TEMPERATURE=0.7
# AI_TIMEOUT_SECONDS=30

# Action Library Path (optional, defaults to ~/.casper/actions)
# ACTION_LIBRARY_PATH=/custom/path/to/actions

# Debug Mode (set to 'true' for verbose logging)
# DEBUG=false
